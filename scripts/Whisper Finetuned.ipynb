{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b530ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42d64e744cfd42a59cffcba5b3cec827",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19e0f4a3ae994bcd883123b99c9016f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/160 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sarve\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\training_args.py:1559: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\sarve\\AppData\\Local\\Temp\\ipykernel_20128\\1178619654.py:60: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(\n",
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.43.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='12' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 3/12 00:32 < 04:55, 0.03 it/s, Epoch 0.44/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Fine-tuning the whisper model\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from datasets import load_dataset, Audio\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "csv_path = r'C:\\Users\\sarve\\Downloads\\Dataset1\\Recordings\\audio__details.csv'\n",
    "audio_folder_path = r'C:\\Users\\sarve\\Downloads\\Dataset1\\Recordings\\train'\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "df['file_name'] = df['file_name'].apply(lambda x: os.path.abspath(os.path.join(audio_folder_path, os.path.basename(x))))\n",
    "df = df[df['file_name'].apply(os.path.exists)]\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "dataset = load_dataset('csv', data_files=csv_path)\n",
    "dataset = dataset.cast_column('file_name', Audio(sampling_rate=16000))\n",
    "dataset = dataset.rename_column('file_name', 'audio')\n",
    "dataset = dataset.rename_column('phrase', 'sentence')\n",
    "\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-base\")\n",
    "\n",
    "def prepare_dataset(batch):\n",
    "    batch[\"input_features\"] = processor(batch[\"audio\"][\"array\"], sampling_rate=16000).input_features[0]\n",
    "    batch[\"labels\"] = processor.tokenizer(batch[\"sentence\"]).input_ids\n",
    "    return batch\n",
    "dataset = dataset.map(prepare_dataset)\n",
    "train_test_split = dataset['train'].train_test_split(test_size=0.1)\n",
    "train_dataset = train_test_split['train']\n",
    "eval_dataset = train_test_split['test']\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-base\")\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"whisper-finetuned1\",\n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=4,\n",
    "    learning_rate=1e-5,\n",
    "    num_train_epochs=3,\n",
    "    fp16=False,\n",
    "    save_steps=100,\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=100,\n",
    "    save_total_limit=2,\n",
    ")\n",
    "class DataCollatorForWhisper:\n",
    "    def __call__(self, features):\n",
    "        input_features = [torch.tensor(feature[\"input_features\"]) for feature in features]\n",
    "        labels = [torch.tensor(feature[\"labels\"]) for feature in features]\n",
    "        input_features_padded = pad_sequence(input_features, batch_first=True, padding_value=0)\n",
    "        labels_padded = pad_sequence(labels, batch_first=True, padding_value=-100)\n",
    "\n",
    "        return {\n",
    "            \"input_features\": input_features_padded,\n",
    "            \"labels\": labels_padded\n",
    "        }\n",
    "\n",
    "data_collator = DataCollatorForWhisper()\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset, \n",
    "    tokenizer=processor.tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "trainer.train()\n",
    "model.save_pretrained(\"whisper-finetuned0\")\n",
    "processor.save_pretrained(\"whisper-finetuned0\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
